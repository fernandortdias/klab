= Semantic modeling with k.LAB
:doctype: book

== Overview

What models are, how they are chosen and what they cause once used.

Models make observations, i.e. _contextualize_ a concept in a context, producing the intended observational artifact through a two-step process: first, the concept is _resolved_ to the best model or models for the context - which, through its dependencies, may cause more resolutions to take place until the system has a strategy to make the observation. Second, the resolved strategy is compiled into a _dataflow_, i.e. a computation that can be run by a runtime system that is unaware of any semantics. Third, the dataflow is run to compute all the observations in the context.

Because all contextualizations are context-dependent, the choice of the overall context for the observation is an arbitrary choice of the user. So the first observation is not computed, but merely _acknowledged_: for example, we may _choose_ to use Italy as a context, and maybe pre-define a resolution and extent for the time and space that we want reflected in the observations. After that initial choice, users can just say what they want and how they want it observed, by querying the k.LAB engine. 

Models make _observations_, and according to the underlying https://github.com/integratedmodelling/odo.html[ontology], the activities that create observational artifacts are of two fundamental types: _resolution_ and _instantiation_.  These, in turn, are subdivided into a few subcategories. The <<section-kim-observable,observable>> declared for the model determines which type of observation activity is encoded in each model. These are relevant to the issue of <<TBD,provenance>>, also discussed elsewhere in this documentation.

It is very typical for all k.LAB models to be very short and very simple. Every model, with few exceptions, is written for _one_ concept, with all its inputs stated merely as semantics, and can be computed and tested as an independent, self-contained module. When the model logics require that certain dependencies are satisfied in a specific way, you use <<modeling-scoping,scoping rules>> to ensure that the specific dependencies you need are picked. It is also possible to use (libraries of) <<TBD,non-semantic models>> to bring in specific computations that have no semantic equivalent worth the effort of annotating, ensuring the linkage with a specific computation without sacrificing modularity. In most situations, models can be written independent of the spatial and temporal context in which they will be run, and often even in ways that are compatible with different interpretations of space and time. Input, output, visualization and contextual validation are all concerns that are left to the k.LAB runtime. In general, writing models this way enforces discipline and maximizes clarity, readability and parsimony: you only write the core computation that leads you to one specific observation, leaving every other aspect (including the selection and computation of any inputs) to the resolver and the k.LAB runtime.

=== The resolution process

=== Dataflows

=== Resources and their lifecycle

In k.LAB, all resources (semantic and not) are identified by a URN. Non-semantic resources represent data sources and computations that are only addressed by name; we call these _artifacts_ and they have two fundamental properties: a _geometry_ and a _type_.

==== URNs

All names used in k.LAB are URNs(REF), identifying both semantic (concepts and models) and non-semantic assets. While the full legal URN syntax can be always used, starting with the prefix `klab:urn:`, in practice short-hand forms are used to ease specification and maximize readability. So for example, the notation `namespace:Concept` using to reference a concept (e.g. `geography:Elevation`) is a shorthand for `klab:urn:klab:im:geography:Elevation`, where the first two parts are the prefix specifying the URN protocol, the third `klab` references the shared k.LAB knowledge space, `im` is the name of the worldview the concept comes from, and the remaining parts define a namespace and a resource ID in it. A model's full name (e.g. `components.geoprocessing.hydrology.curve-number-resolver`) is a shorthand for `klab:urn:klab:im.components.geoprocessing:components.geoprocessing.hydrology:curve-number-resolver`, where the fourth token is the name of the project containing the `curve-number-resolver` model in the `components.geoprocessing:components` namespace . While the k.LAB API understands all these fully specified URNs and uses them in its internal referencing, users do not need to worry about their full specification; in fact, the k.IM language only admits the short-hand notation for concepts and models.

In k.IM we use four-part URN shorthands for **non-semantic resources**, composed of four mandatory parts plus an optional _postfix_ part (following an optional pound `#` sign). Such URNs uniquely identify a source of knowledge that can be linked to a semantic URN (e.g. a concept) to make it available to the k.LAB engine; the postfix can be seen as parameters to select particular views or portions of that source. The general scheme for a k.LAB resource URN is

   <node>:<catalog>:<namespace>:<resource-id>
   
All of the tokens can be single identifiers or dot-separated paths. The first token, the `node` identifier, may have the special values `klab` and `local` in addition to specifying a node locator. These cases define three different classes of URNs:

[horizontal]
*klab*:: _universal_ URNs that have no associated content, and are interpreted directly by an engine. These have the string `klab` as the node element and an `adapter` identifier as the catalog element.  The adapter selects a software component that will resolve the URN to extract information from it. For example, the string `klab:osm:relation:2202162` is processed by the `osm` adapter and will produce the Open Street Map relation identified by 2202162, corresponding to the country of France. 
*local*:: _local_ URNs are associated to locally hosted project content and metadata. physically located in a subfolder within a project's `resources` directory. These have the string `local` as the node element; the catalog element is the username of the contributor that created the resource, and the namespace will be the name of the project that contains them. These are created by importing external data or services (or sometimes as the output of <<TBD,learning models>>) and, once valid and properly documented, can be _published_ to become public resources, served by k.LAB <<TBD,nodes>> and available to all users. Within the project that contains them, these resources can be identified by just mentioning the last element, so if the resource names a file, the file name will be enough to refer to it in a model. Projects that contain or use local resources cannot be published for shared use: before publication, all resources must be published on nodes and the URNs must be changed to refer to the public resources.
*public*:: _public_ resources have a _node name_ (usually a dot-separated hostname) as their first element, and can be referenced within any project as they are resolved and served through the network. They start their lifecycle as local resources and are given their final, immutable URN after publication. As nodes can mirror each other's resources, the node that will eventually serve the resource may not be the one named in the URN; still, the URN remains immutable after creation, even if it is moved to a different node, still referencing the name of the node where it was originally published.

Resources identified by URNs may be online or offline: the latter state happens when the resource references a web service that is not reachable or when the adapter that interprets them is not available. Any models that use an offline resource will be _void_ and not available to make observations. The k.LAB <<TBD,modeler>> shows such models in grey and italics in the editor. Resources that are known and online will appear in dark green nd bold type.



URNs may also include a _version_ and _parameters_ after the first four elements. Versions can only be used in public URNs and can be used to refer to previous versions (if the version number is omitted, the latest version of the resource will be used). Parameters, appended at the end following a pound sign (`#`), may be used to select specific subsets of the data (for example a specific column or field in tabular data or an attribute of object data) or to pass options to computations.

...more, examples

==== Resource type

==== Geometry
... type and geometry

=== Provenance

== Semantic modeling in practice

=== Types of models and observations

=== Learning models

[#modeling-scoping]
=== Scoping

If any k.LAB model could use any other k.LAB model on the network to satisfy its dependencies, and contribute its observable to any model made by any user without discrimination, it would be very difficult to ensure proper results. 

Model choice:

1. Scenario
2. Private in same namespace
3. Public in same namespace
4. Public in parent namespace (in order of distance)
5. Project private in same project
6. Public local or cached
7. Public from the network

=== What does the work: contextualizers

=== Procedural knowledge: language bridges

The k.LAB stack can be extended to accommodate extension languages within its expressions. If no language is specified, the <<modeling-language-groovy,default k.IM expression language>> is used. 

Writing a language adapter is no small task if smooth integration with the k.LAB environment is desired, with handling of concepts, observation etc. Yet, it can be much simpler for more basic integration such as producing additional variables. For example, a simple adapter to R (using http://renjin.org[Renjin]) could be written to simply provide R-computed outputs to use later in the default language, as in:

[source,kim]
----
model ....
	observing 
		....
	set r_out to [....] using R
	set to [r_out.p < 0.05 ? significant : insignificant];
----

To support the code above, all the language bridge has to go is to collect inputs from k.LAB. According to what the guest language produces, translation of the outputs to a more idiomatic API may be desirable, but if the outputs are Java-compatible, the Groovy compiler in the default language will take care of everything else.

==== Controlling resolution

==== Scaling and contextualization

===== Units and context

==== Non-semantic models

[#modeling-language-groovy]
== The expression language

== Components in k.LAB

Modes of extension:

- Contextualizers
- Adapters
- Language bridges

See the developer documentation to learn how to define components.

include::./modeling/random.adoc[]

include::./modeling/weather.adoc[]

include::./modeling/gis.adoc[]

include::./modeling/mca.adoc[]

include::./modeling/ml.adoc[]

