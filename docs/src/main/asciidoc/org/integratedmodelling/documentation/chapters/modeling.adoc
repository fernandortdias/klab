= Semantic modeling with k.LAB
:doctype: book

== Overview

What models are, how they are chosen and what they cause once used.

Models make observations, i.e. _contextualize_ a concept in a context, producing the intended observational artifact through a two-step process: first, the concept is _resolved_ to the best model or models for the context - which, through its dependencies, may cause more resolutions to take place until the system has a strategy to make the observation. Second, the resolved strategy is compiled into a _dataflow_, i.e. a computation that can be run by a runtime system that is unaware of any semantics. Third, the dataflow is run to compute all the observations in the context.

Because all contextualizations are context-dependent, the choice of the overall context for the observation is an arbitrary choice of the user. So the first observation is not computed, but merely _acknowledged_: for example, we may _choose_ to use Italy as a context, and maybe pre-define a resolution and extent for the time and space that we want reflected in the observations. After that initial choice, users can just say what they want and how they want it observed, by querying the k.LAB engine. 

Models make _observations_, and according to the underlying https://github.com/integratedmodelling/odo.html[ontology], the activities that create observational artifacts are of two fundamental types: _resolution_ and _instantiation_.  These, in turn, are subdivided into a few subcategories. The <<section-kim-observable,observable>> declared for the model determines which type of observation activity is encoded in each model. These are relevant to the issue of <<TBD,provenance>>, also discussed elsewhere in this documentation.

It is very typical for all k.LAB models to be very short and very simple. Every model, with few exceptions, is written for _one_ concept, with all its inputs stated merely as semantics, and can be computed and tested as an independent, self-contained module. When the model logics require that certain dependencies are satisfied in a specific way, you use <<modeling-scoping,scoping rules>> to ensure that the specific dependencies you need are picked. It is also possible to use (libraries of) <<TBD,non-semantic models>> to bring in specific computations that have no semantic equivalent worth the effort of annotating, ensuring the linkage with a specific computation without sacrificing modularity. In most situations, models can be written independent of the spatial and temporal context in which they will be run, and often even in ways that are compatible with different interpretations of space and time. Input, output, visualization and contextual validation are all concerns that are left to the k.LAB runtime. In general, writing models this way enforces discipline and maximizes clarity, readability and parsimony: you only write the core computation that leads you to one specific observation, leaving every other aspect (including the selection and computation of any inputs) to the resolver and the k.LAB runtime.

=== The resolution process

=== Dataflows

=== The resource lifecycle

=== Provenance

== Semantic modeling in practice

=== Types of models and observations

=== Learning models

[#modeling-scoping]
=== Scope

If any k.LAB model could use any other k.LAB model on the network to satisfy its dependencies, and contribute its observable to any model made by any user without discrimination, it would be very difficult to ensure proper results. 

=== What does the work: contextualizers

=== Procedural knowledge: language bridges

The k.LAB stack can be extended to accommodate extension languages within its expressions. If no language is specified, the <<modeling-language-groovy,default k.IM expression language>> is used. 

Writing a language adapter is no small task if smooth integration with the k.LAB environment is desired, with handling of concepts, observation etc. Yet, it can be much simpler for more basic integration such as producing additional variables. For example, a simple adapter to R (using http://renjin.org[Renjin]) could be written to simply provide R-computed outputs to use later in the default language, as in:

[source,kim]
----
model ....
	observing 
		....
	set r_out to [....] using R
	set to [r_out.p < 0.05 ? significant : insignificant];
----

To support the code above, all the language bridge has to go is to collect inputs from k.LAB. According to what the guest language produces, translation of the outputs to a more idiomatic API may be desirable, but if the outputs are Java-compatible, the Groovy compiler in the default language will take care of everything else.

==== Controlling resolution

==== Scaling and contextualization

===== Units and context

==== Non-semantic models

[#modeling-language-groovy]
== The expression language

== Components in k.LAB

Modes of extension:

- Contextualizers
- Adapters
- Language bridges

See the developer documentation to learn how to define components.

include::./modeling/gis.adoc[]

include::./modeling/mca.adoc[]

include::./modeling/weka.adoc[]
