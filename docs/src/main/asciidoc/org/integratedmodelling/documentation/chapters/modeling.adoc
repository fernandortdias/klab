= Semantic modeling with k.LAB
A guide to the semantic modeling with k.LAB and the k.IM language.
v1.0, 2021-02-20
:doctype: article
:description: Chat about resources handling with Villa
:kl: k.LAB
:kmod: k.Modeler
:kact: k.Actors
:keng: k.LAB Engine
:knod: k.LAB Node
:kim: k.IM
:ked: k.LAB Resource Editor
:pex: k.LAB Explorer
:kex: Project Explorer
:encoding: utf-8
:lang: en
:title-page:
:toc: left
:toclevels: 5
:sectnums:
:sectnumlevels: 5
:numbered:
:experimental:
:reproducible:
:icons: font
:listing-caption: Listing
:sectnums:
:autofit-option:
:mdash: &#8212;
:language: asciidoc
ifdef::backend-pdf[]
:title-logo-image: image:imgs/KLAB_LOGO.png[align=center]
:source-highlighter: rouge
//:rouge-style: github
//:source-highlighter: pygments
//:pygments-style: tango
endif::[]
:stem:

<<<

== Overview

Models, as commonly understood in scientific practice, are computational or logical processes that create scientific artifacts that describe a phenomenon of interest, for example the numeric measurement of a property such as atmospheric temperature, or its change over time under the effect of a hypothesized stressor. A "model" of rainfall may use a static dataset (for previous field measurements) or a computed best-guess (for example to fill holes in available data). A "model" of climate change will need to incorporate many factors, hypotheses and assumptions to predict that same phenomenon over, say, the next 50 years. All of these are everyday questions in scientific investigation, and they currently require major efforts on behalf of investigators, to find, assemble, process, verify input data, then manually run any software that implements the model to obtain outputs.

The {kl} technology is dedicated to providing a systematic, reliable process to streamline the scientific observation process by _reusing_ data and models, making them _findable_ and _accessible_ over the network, and ensuring their _integration_ by design. This is done by providing languages and infrastructure to:

1. identify _observable_ concepts (the _semantics_) for the phenomena under investigation, then 
2. write concise statements that specify how to create scientific artifacts (observations) of _each_ observable, which describes both the model and the resulting observation. 

These models, potentially restricted to apply to specified spatial or temporal context of usage, are made available on the network to contribute to a distributed knowledge base. Once such a knowledge base is available, it can be used to _resolve_ ... using existing data and models adaptively, efficiently and with no duplication of effort. This is obtained through a two-step process: first, the concept is _resolved_ to the best model or models for the context - which, through its dependencies, may cause more resolutions to take place until the system has a strategy to make the observation. Second, the resolved strategy is compiled into a _dataflow_, i.e. a computation that can be run by a runtime system that is unaware of any semantics. Third, the dataflow is run to compute all the observations in the context.

In other words, models describe an _observation activity_; this activity will operate differently according to the _core type_ of the observable. For example, observing the elevation in a region will be a _quantification_ of its value in each point at the observational scale. Observing the land cover type will be a _classification_; observing cars or elections in the region will require _instantiation_ of the correspondent objects or events; while observing the water flow or a governance process will require a _simulation_. In general, all activities that create observational artifacts are of two fundamental types: _resolution_ and _instantiation_. These, in turn, are subdivided into a few more subcategories. The  https://github.com/integratedmodelling/odo-im[ontology] that underlies {kl} describes all these types, which are relevant to the issue of <<TBD,provenance>>, discussed elsewhere in this documentation.

It is important to understand that there is always a main observation (in the examples above, a region) which represents the _context_ for all others, and is an arbitrary choice of the user. The first observation is merely _acknowledged_: for example, we may _choose_ to use Italy as a context, and that choice will pre-define a resolution and extent for the time and space that we want reflected in the observations. After that initial choice, users can just say what they want and how they want it observed, by querying the k.LAB engine. But the inherent human-centric relativity of the scientific observation process cannot be escaped, here or in any other scientific endeavor: one must always _choose_ what to look at and, to some extent, _how_ to look at it. The process of semantic modeling embraces this relativity, while making it explicit.

Models make _observations_, and according to the underlying https://github.com/integratedmodelling/odo-im[ontology], the activities that create observational artifacts are of two fundamental types: _resolution_ and _instantiation_.  These, in turn, are subdivided into a few more subcategories. The <<section-kim-observable,observable>> declared for the model determines which type of observation activity is specified by each model. These are relevant to the issue of <<TBD,provenance>>, discussed elsewhere in this documentation.

It is very typical for all k.LAB models to be very short and very simple. Every model, with few exceptions, is written for _one_ concept, with all its inputs stated merely as semantics, and can be computed and tested as an independent, self-contained module. When the model logics require that certain dependencies are satisfied in a specific way, you use <<modeling-scoping,scoping rules>> to ensure that the specific dependencies you need are picked. It is also possible to use (libraries of) <<TBD,non-semantic models>> to bring in specific computations that have no semantic equivalent worth the effort of annotating, ensuring the linkage with a specific computation without sacrificing modularity. In most situations, models can be written independent of the spatial and temporal context in which they will be run, and often even in ways that are compatible with different interpretations of space and time. Input, output, visualization and contextual validation are all concerns that are left to the k.LAB runtime. In general, writing models this way enforces discipline and maximizes clarity, readability and parsimony: you only write the core computation that leads you to one specific observation, leaving every other aspect (including the selection and computation of any inputs) to the resolver and the k.LAB runtime.

=== The resolution process

=== Dataflows

=== Resources and their lifecycle

In k.LAB, all resources (semantic and not) are identified by a URN. Non-semantic resources represent data sources and computations that are only addressed by name; we call these _artifacts_ and they have two fundamental properties: a _geometry_ and a _type_.

==== URNs

All names used in k.LAB are URNs(REF), identifying both semantic (concepts and models) and non-semantic assets. While the full legal URN syntax can be always used, starting with the prefix `klab:urn:`, in practice short-hand forms are used to ease specification and maximize readability. So for example, the notation `namespace:Concept` using to reference a concept (e.g. `geography:Elevation`) is a shorthand for `klab:urn:klab:im:geography:Elevation`, where the first two parts are the prefix specifying the URN protocol, the third `klab` references the shared k.LAB knowledge space, `im` is the name of the worldview the concept comes from, and the remaining parts define a namespace and a resource ID in it. A model's full name (e.g. `components.geoprocessing.hydrology.curve-number-resolver`) is a shorthand for `klab:urn:klab:im.components.geoprocessing:components.geoprocessing.hydrology:curve-number-resolver`, where the fourth token is the name of the project containing the `curve-number-resolver` model in the `components.geoprocessing:components` namespace . While the k.LAB API understands all these fully specified URNs and uses them in its internal referencing, users do not need to worry about their full specification; in fact, the k.IM language only admits the short-hand notation for concepts and models.

In k.IM we use four-part URN shorthands for **non-semantic resources**, composed of four mandatory parts plus an optional _postfix_ part (following an optional pound `#` sign). Such URNs uniquely identify a source of knowledge that can be linked to a semantic URN (e.g. a concept) to make it available to the k.LAB engine; the postfix can be seen as parameters to select particular views or portions of that source. The general scheme for a k.LAB resource URN is

   <node>:<catalog>:<namespace>:<resource-id>
   
All of the tokens can be single identifiers or dot-separated paths. The first token, the `node` identifier, may have the special values `klab` and `local` in addition to specifying a node locator. These cases define three different classes of URNs:

[horizontal]
*klab*:: _universal_ URNs that have no associated content, and are interpreted directly by an engine. These have the string `klab` as the node element and an `adapter` identifier as the catalog element.  The adapter selects a software component that will resolve the URN to extract information from it. For example, the string `klab:osm:relation:2202162` is processed by the `osm` adapter and will produce the Open Street Map relation identified by 2202162, corresponding to the country of France. 
*local*:: _local_ URNs are associated to locally hosted project content and metadata. physically located in a subfolder within a project's `resources` directory. These have the string `local` as the node element; the catalog element is the username of the contributor that created the resource, and the namespace will be the name of the project that contains them. These are created by importing external data or services (or sometimes as the output of <<TBD,learning models>>) and, once valid and properly documented, can be _published_ to become public resources, served by k.LAB <<TBD,nodes>> and available to all users. Within the project that contains them, these resources can be identified by just mentioning the last element, so if the resource names a file, the file name will be enough to refer to it in a model. Projects that contain or use local resources cannot be published for shared use: before publication, all resources must be published on nodes and the URNs must be changed to refer to the public resources.
*public*:: _public_ resources have a _node name_ (usually a dot-separated hostname) as their first element, and can be referenced within any project as they are resolved and served through the network. They start their lifecycle as local resources and are given their final, immutable URN after publication. As nodes can mirror each other's resources, the node that will eventually serve the resource may not be the one named in the URN; still, the URN remains immutable after creation, even if it is moved to a different node, still referencing the name of the node where it was originally published.

Resources identified by URNs may be online or offline: the latter state happens when the resource references a web service that is not reachable or when the adapter that interprets them is not available. Any models that use an offline resource will be _void_ and not available to make observations. The k.LAB <<TBD,modeler>> shows such models in grey and italics in the editor. Resources that are known and online will appear in dark green nd bold type.



URNs may also include a _version_ and _parameters_ after the first four elements. Versions can only be used in public URNs and can be used to refer to previous versions (if the version number is omitted, the latest version of the resource will be used). Parameters, appended at the end following a pound sign (`#`), may be used to select specific subsets of the data (for example a specific column or field in tabular data or an attribute of object data) or to pass options to computations.

...more, examples

==== Resource type

==== Geometry
... type and geometry

=== Provenance

== Semantic modeling in practice

=== Types of models and observations

=== Learning models

[#modeling-scoping]
=== Scoping

If any k.LAB model could use any other k.LAB model on the network to satisfy its dependencies, and contribute its observable to any model made by any user without discrimination, it would be very difficult to ensure proper results. 

Model choice:

1. Scenario
2. Private in same namespace
3. Public in same namespace
4. Public in parent namespace (in order of distance)
5. Project private in same project
6. Public local or cached
7. Public from the network

=== What does the work: contextualizers

=== Procedural knowledge: language bridges

The k.LAB stack can be extended to accommodate extension languages within its expressions. If no language is specified, the <<modeling-language-groovy,default k.IM expression language>> is used. 

Writing a language adapter is no small task if smooth integration with the k.LAB environment is desired, with handling of concepts, observation etc. Yet, it can be much simpler for more basic integration such as producing additional variables. For example, a simple adapter to R (using http://renjin.org[Renjin]) could be written to simply provide R-computed outputs to use later in the default language, as in:

[source,kim]
----
model ....
	observing 
		....
	set r_out to [....] using R
	set to [r_out.p < 0.05 ? significant : insignificant];
----

To support the code above, all the language bridge has to go is to collect inputs from k.LAB. According to what the guest language produces, translation of the outputs to a more idiomatic API may be desirable, but if the outputs are Java-compatible, the Groovy compiler in the default language will take care of everything else.

==== Controlling resolution

==== Scaling and contextualization

===== Units and context

==== Non-semantic models

[#modeling-language-groovy]
== The expression language

== Components in k.LAB

Modes of extension:

- Contextualizers
- Adapters
- Language bridges

See the developer documentation to learn how to define components.

=== Debugging

Situations that arise most commonly during modeling

==== Resolution

A common concern is when the model picked by the system to resolve a particular concept is not the one the modeler expects. Resolution prioritization is complex and it helps to visualize the set of criteria used by the prioritizer. This can be done by setting the `klab.debugging.resolution.ranks` property to true, either permanently in the ~/.klab.properties file or manually in the engine command line window:

----
set klab.debugging.resolution.ranks true
----

After this is done, each resolution will print all the models found to resolve each concept, in order of priority (chosen model first), each followed by the rankings for each criterion chosen (the criteria may be different from what you see below):

----
model query for explanation of [land_cover_type = landcover:LandCoverType] found 2 models
---- SCORES ------
  1.  data.global.landcover.land-cover-type-resolver [local]
    im:lexical-scope          0.0
    im:semantic-concordance   0.0
    im:trait-concordance      100.0
    im:evidence               100.0
    im:time-specificity       71.04657534246576
    im:time-coverage          100.0
    im:space-specificity      0.035397563347683014
    im:space-coverage         100.0
    im:subjective-concordance 50.0
    im:inherency              0.0

  2.  data.global.landcover.corine_land_cover [local]
    im:lexical-scope          0.0
    im:semantic-concordance   0.0
    im:trait-concordance      100.0
    im:evidence               100.0
    im:time-specificity       69.04657534246576
    im:time-coverage          100.0
    im:space-specificity      1.1905609130529544
    im:space-coverage         49.13483424377154
    im:subjective-concordance 50.0
    im:inherency              0.0

------------------
accepting data.global.landcover.land-cover-type-resolver to resolve 100% of [land_cover_type = landcover:LandCoverType]
----

Inspecting the scores can be very useful to understand, and possibly change, why the resolver pick each specific model. If an expected model does not appear in the list, it probably has errors or is out of scope of the resolution.

==== The context debugger

Since build 234, k.LAB incorporates a simple _context debugger_ that is useful to inspect values and track their change when they are part of large and complex contexts, such as a raster space. 

TODO debugger usage

include::./modeling/random.adoc[]

include::./modeling/weather.adoc[]

include::./modeling/gis.adoc[]

include::./modeling/mca.adoc[]

include::./modeling/ml.adoc[]

