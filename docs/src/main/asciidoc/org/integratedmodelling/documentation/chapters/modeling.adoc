= Semantic modeling with k.LAB
:doctype: book

== Overview

What models are, how they are chosen and what they cause once used.

Models make observations, i.e. _contextualize_ a concept in a context, producing the intended observational artifact through a two-step process: first, the concept is _resolved_ to the best model or models for the context - which, through its dependencies, may cause more resolutions to take place until the system has a strategy to make the observation. Second, the resolved strategy is compiled into a _dataflow_, i.e. a computation that can be run by a runtime system that is unaware of any semantics. Third, the dataflow is run to compute all the observations in the context.

Because all contextualizations are context-dependent, the choice of the overall context for the observation is an arbitrary choice of the user. So the first observation is not computed, but merely _acknowledged_: for example, we may _choose_ to use Italy as a context, and maybe pre-define a resolution and extent for the time and space that we want reflected in the observations. After that initial choice, users can just say what they want and how they want it observed, by querying the k.LAB engine. 

Models make _observations_, and according to the underlying https://github.com/integratedmodelling/odo.html[ontology], the activities that create observational artifacts are of two fundamental types: _resolution_ and _instantiation_.  These, in turn, are subdivided into a few subcategories. The <<section-kim-observable,observable>> declared for the model determines which type of observation activity is encoded in each model. These are relevant to the issue of <<TBD,provenance>>, also discussed elsewhere in this documentation.

It is very typical for all k.LAB models to be very short and very simple. Every model, with few exceptions, is written for _one_ concept, with all its inputs stated merely as semantics, and can be computed and tested as an independent, self-contained module. When the model logics require that certain dependencies are satisfied in a specific way, you use <<modeling-scoping,scoping rules>> to ensure that the specific dependencies you need are picked. It is also possible to use (libraries of) <<TBD,non-semantic models>> to bring in specific computations that have no semantic equivalent worth the effort of annotating, ensuring the linkage with a specific computation without sacrificing modularity. In most situations, models can be written independent of the spatial and temporal context in which they will be run, and often even in ways that are compatible with different interpretations of space and time. Input, output, visualization and contextual validation are all concerns that are left to the k.LAB runtime. In general, writing models this way enforces discipline and maximizes clarity, readability and parsimony: you only write the core computation that leads you to one specific observation, leaving every other aspect (including the selection and computation of any inputs) to the resolver and the k.LAB runtime.

=== The resolution process

=== Dataflows

=== Resources and their lifecycle

In k.LAB, all resources (semantic and not) are identified by a URN. Non-semantic resources represent data sources and computations that are only addressed by name; we call these _artifacts_ and they have two fundamental properties: a _geometry_ and a _type_.

==== URNs

All names used in k.LAB are URNs[], and they can be written in their extended and legal form by prefixing them with `klab:urn:`. In practice, the extended form is cumbersome and better left to machines. In the k.IM language and all interfaces for k.LAB, we can see URNs for non-semantic resources as composed of four mandatory parts plus optional _postfix_ part. The general scheme for a k.LAB resource URN is

   <node>:<catalog>:<namespace>:<resource-id>
   
The first part, the `node` identifier, may have the special values `klab` and `local`, defining three different classes of URNs:

[horizontal]
*klab*:: _universal_ URNs that have no associated content, and are interpreted directly by an engine. These have the string `klab` as the node element and an `adapter` identifier as the catalog element.  The adapter selects the software processor that will resolve the URN in the k.LAB engine. For example, the string `klab:osm:relation:2202162` is processed by the `osm` adapter and will produce the Open Street Map relation identified by 2202162, corresponding to the country of France. 
*local*:: _local_ URNs associated to locally hosted content and metadata (physically located in a subfolder within a project's `resources` directory). These have the string `local` as the node element; the catalog element is the username of the contributor that created the resource, and the namespace will be the name of the project that contains them. These are created by importing external data or services (or sometimes as the output of <<TBD,learning models>>) and, once valid and properly documented, can be _published_ to become public resources, served by k.LAB <<TBD,nodes>> and available to all users. Within the project that contains them, these resources can be identified by just mentioning the last element, so if the resource names a file, the file name will be enough to refer to it in a model.
*public*:: _public_ resource have a _node name_ (usually a dot-separated hostname) as their first element, and can be referenced within any project as they are resolved and served through the network. They start their lifecycle as local resources and are given their final, immutable URN after publication. As nodes can mirror each other's resources, the node that will eventually serve the resource may not be the one named in the URN; the URN remains immutable after creation, even if it is moved to a different node, still referencing the name of the node where it was originally published.

URNs may be online or offline: the latter state happens when the resource references a web service that is not reachable or when the adapter that interprets them is not available. Any models that use an offline resource will be _void_ and not available to make observations. The k.LAB <<TBD,modeler>> shows such models in grey and italics in the editor. Resources that are known and online will appear in dark green nd bold type.

All knowledge is referenced as URNs in k.LAB, including semantic resources (concepts and models). In these cases, the URN used by modelers and users can be referenced in a short-hand form. So for example, the notation `namespace:Concept` using to reference a concept (e.g. `geography:Elevation`) can be thought of as a shorthand for `klab:im:geography:Elevation`, where `im` is the name of the worldview the concept comes from. At the same time, a model's full name (e.g. `components.geoprocessing.hydrology.curve-number-resolver`) is a shorthand for `klab:im.components.geoprocessing:components.geoprocessing.hydrology:curve-number-resolver`, where the catalog token is the name of the project containing the `curve-number-resolver` model in the `components.geoprocessing:components` namespace . While the k.LAB API understands all these fully specified URNs and uses them in its internal referencing, users do not need to worry about their full specification; the k.IM language only accepts short-hand notation for concepts and models.

URNs may also include a _version_ and _parameters_ after the first four elements. Versions can only be used in public URNs and can be used to refer to previous versions (if the version number is omitted, the latest version of the resource will be used). Parameters, appended at the end following a pound sign (`#`), may be used to select specific subsets of the data (for example a specific column or field in tabular data or an attribute of object data) or to pass options to computations.

...more, examples

==== Resource type

==== Geometry
... type and geometry

=== Provenance

== Semantic modeling in practice

=== Types of models and observations

=== Learning models

[#modeling-scoping]
=== Scope

If any k.LAB model could use any other k.LAB model on the network to satisfy its dependencies, and contribute its observable to any model made by any user without discrimination, it would be very difficult to ensure proper results. 

=== What does the work: contextualizers

=== Procedural knowledge: language bridges

The k.LAB stack can be extended to accommodate extension languages within its expressions. If no language is specified, the <<modeling-language-groovy,default k.IM expression language>> is used. 

Writing a language adapter is no small task if smooth integration with the k.LAB environment is desired, with handling of concepts, observation etc. Yet, it can be much simpler for more basic integration such as producing additional variables. For example, a simple adapter to R (using http://renjin.org[Renjin]) could be written to simply provide R-computed outputs to use later in the default language, as in:

[source,kim]
----
model ....
	observing 
		....
	set r_out to [....] using R
	set to [r_out.p < 0.05 ? significant : insignificant];
----

To support the code above, all the language bridge has to go is to collect inputs from k.LAB. According to what the guest language produces, translation of the outputs to a more idiomatic API may be desirable, but if the outputs are Java-compatible, the Groovy compiler in the default language will take care of everything else.

==== Controlling resolution

==== Scaling and contextualization

===== Units and context

==== Non-semantic models

[#modeling-language-groovy]
== The expression language

== Components in k.LAB

Modes of extension:

- Contextualizers
- Adapters
- Language bridges

See the developer documentation to learn how to define components.

include::./modeling/gis.adoc[]

include::./modeling/mca.adoc[]

include::./modeling/weka.adoc[]
