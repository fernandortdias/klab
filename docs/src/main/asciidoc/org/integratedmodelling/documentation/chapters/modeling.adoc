= Semantic modeling with k.LAB
:doctype: book

== Overview

What models are, how they are chosen and what they cause once used.

Models make observations, i.e. _contextualize_ a concept in a context, producing the observational artifact throug a two-step process: first, the concept is _resolved_ to the best model or models for the context - which, through its dependencies, may cause more resolutions to take place until the system has a strategy to make the observation. Second, the resolved strategy is compiled into a _dataflow_, i.e. a computation that can be run by a runtime system that is unaware of any semantics. Third, the dataflow is run to compute all the observations in the context.

Because all contextualizations are context-dependent, the choice of the overall context for the observation is an arbitrary choice of the user. So the first observation is not computed, but merely _acknowledged_: for example, we may _choose_ to use Italy as a context, and maybe pre-define a resolution and extent for the time and space that we want reflected in the observations. After that initial choice, users can just say what they want and how they want it observed, by querying the k.LAB engine. 

Models make _observations_, and according to the underlying https://github.com/integratedmodelling/odo.html[ontology], the activities that create observational artifacts are of two fundamental types: _resolution_ and _instantiation_.  These, in turn, are subdivided into a few subcategories. The <<section-kim-observable,observable>> declared for the model determines which type of observation activity is encoded in each model.



=== The resolution process

=== Dataflows

=== The resource lifecycle

=== Provenance

== Semantic modeling in practice

=== Types of models and observations

=== Learning models

=== Scope

=== What does the work: contextualizers

=== Procedural knowledge: language bridges

The k.LAB stack can be extended to accommodate extension languages within its expressions. If no language is specified, the <<modeling-language-groovy,default k.IM expression language>> is used. 

Writing a language adapter is no small task if smooth integration with the k.LAB environment is desired, with handling of concepts, observation etc. Yet, it can be much simpler for more basic integration such as producing additional variables. For example, a simple adapter to R (using http://renjin.org[Renjin]) could be written to simply provide R-computed outputs to use later in the default language, as in:

[source,kim]
----
model ....
	observing 
		....
	set r_out to [....] using R
	set to [r_out.p < 0.05 ? significant : insignificant];
----

To support the code above, all the language bridge has to go is to collect inputs from k.LAB. According to what the guest language produces, translation of the outputs to a more idiomatic API may be desirable, but if the outputs are Java-compatible, the Groovy compiler in the default language will take care of everything else.

==== Controlling resolution

==== Scaling and contextualization

===== Units and context

==== Non-semantic models

[#modeling-language-groovy]
== The expression language

== Components in k.LAB

Modes of extension:

- Contextualizers
- Adapters
- Language bridges

See the developer documentation to learn how to define components.

include::./modeling/gis.adoc[]

include::./modeling/mca.adoc[]

include::./modeling/weka.adoc[]
