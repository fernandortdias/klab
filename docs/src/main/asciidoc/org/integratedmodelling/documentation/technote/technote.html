<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.15">
<meta name="description" content="High-level technical description of k.LAB for technical partners">
<meta name="author" content="Technical note">
<title>k.LAB: a semantic web platform for science</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:50%;border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>k.LAB: a semantic web platform for science</h1>
<div class="details">
<span id="author" class="author">Technical note</span><br>
<span id="revnumber">version 1.0,</span>
<span id="revdate">2021-02-20</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_architecture_of_the_k_lab_platform">1. Architecture of the k.LAB platform</a>
<ul class="sectlevel2">
<li><a href="#_the_software_stack">1.1. The software stack</a></li>
<li><a href="#_the_k_lab_logical_layers">1.2. The k.LAB logical layers</a></li>
<li><a href="#_accessing_the_system">1.3. Accessing the system</a></li>
</ul>
</li>
<li><a href="#_the_resource_layer">2. The resource layer</a></li>
<li><a href="#_semantic_modeling">3. Semantic modeling</a>
<ul class="sectlevel2">
<li><a href="#_semantic_mediation_and_inference_in_support_of_modeling">3.1. Semantic mediation and inference in support of modeling</a></li>
<li><a href="#_the_worldview">3.2. The worldview</a>
<ul class="sectlevel3">
<li><a href="#_authorities">3.2.1. Authorities</a></li>
</ul>
</li>
<li><a href="#_learning_models">3.3. Learning models</a></li>
<li><a href="#_views_documentation_provenance">3.4. Views, documentation, provenance</a></li>
</ul>
</li>
<li><a href="#_behaviors_and_applications">4. Behaviors and applications</a>
<ul class="sectlevel2">
<li><a href="#_applications_client_software">4.1. Applications, Client software</a></li>
</ul>
</li>
<li><a href="#_current_status">5. Current status</a></li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div style="page-break-after: always;"></div>
<div class="paragraph">
<p><strong>Integrated modeling</strong> is a practice meant to maximize the value of scientific information by ensuring its  <em>modularity</em>, <em>reusability</em>, <em>interoperability</em> and <em>traceability</em> throughout the scientific process. The k.LAB software, discussed here, is a full-stack solution for integrated modelling, supporting the production, curation, linking and deployment of scientific artifacts such as datasets, data services, modular model components and distributed computational services. The purpose of k.LAB is to ensure&#8201;&#8212;&#8201;by <em>design</em> rather than intention&#8201;&#8212;&#8201;that the pool of such artifacts constitutes a seamless <em>knowledge commons</em>, readily actionable (by humans or machines) through the full realization of the <em>linked data</em> paradigm [REF] augmented with semantics and powered by machine reasoning. This design enables automation of a wide range of modeling tasks that were previously only performable by experts and on an ad-hoc basis.</p>
</div>
<div class="paragraph">
<p>The k.LAB platform directly addresses the four FAIR goals (Findable, Accessible, Interoperable and Reusable), introducing innovations particularly in the practice of semantic annotation,  which is reviewed into a modern, expressive approach meant to ease adoption by providers and users. To the four dimensions in FAIR, k.LAB adds a <em>reactivity</em> dimension, in line with the original vision of a semantic web: this dimension enables knowledge to also be <em>deployed</em> in an <em>"internet of observations"</em>, creating <em>live</em> artifacts that can interact, improve and evolve as new information appears on the network.</p>
</div>
<div class="paragraph">
<p>The central service in the k.LAB modeling API wraps the RESOLUTION ALGORITHM !!!! receives as input a logical query of the form "observe <em>concept</em> in <em>context</em>" (e.g., "observe <em>change in land cover type</em> in <em>Colombia, 2015-2020</em>", only slightly paraphrased from k.LAB&#8217;s near-natural query formalism) and, in response, assembles, documents, initializes and runs a computation (called a <em>dataflow</em>) that produces the  <strong>observation</strong> of the concept that best fits the context, based on the integration of data and model components available in the k.LAB network. The observations output by the API request, along with the dataflow assembled to generate them, are themselves scientific artifacts&#8201;&#8212;&#8201;automatically augmented with provenance records and user-readable documentation&#8201;&#8212;&#8201;that can be exported and curated as needed. @!!!! The logical queries are also used to state model dependencies so that &#8230;&#8203;. !!!!</p>
</div>
<div class="paragraph">
<p>Artificial intelligence, driven by both semantics (<em>machine reasoning</em>) and the analysis of previous outcomes (<em>machine learning</em>), satisfies the request using a shared, communally owned and curated knowledge base (the <em>worldview</em>, a set of ontologies) and the resource pool available at any given moment on the k.LAB network, by ranking, selecting, adapting, and connecting data and model components made available by independent and uncoordinated providers.</p>
</div>
<div class="paragraph">
<p>This document is a brief sketch of the k.LAB main principles and architecture. Detailed documentation for k.LAB is in development and is referenced where available.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_architecture_of_the_k_lab_platform">1. Architecture of the k.LAB platform</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The open source k.LAB software stack includes five components that support the creation, maintenance and use of a distributed <em>semantic web platform</em> where scientific information can be stored, published, curated and connected. The software is licensed through the Affero General Public License (AGPL) v.3.0 and is available for the most part at the <a href="https://bitbucket.org/integratedmodelling/klab">k.LAB git repository</a>.</p>
</div>
<div class="sect2">
<h3 id="_the_software_stack">1.1. The software stack</h3>
<div class="ulist">
<ul>
<li>
<p><strong>Server</strong> components are deployed by certified <em>partners</em> to publish resources and semantic content (<strong>k.LAB Node</strong>) and/or provide modeling services and applications (<strong>k.LAB Engine</strong>) to online users. Published resources can include both static data and dynamic computations, both of which may be hosted in source form at the node or linked to external data (e.g. WCS, WFS, OpenDAP) or computational services (e.g. OpenCPU). The k.Node software is deployed in containers that can be configured to host dedicated instances of Geoserver, PostgreSQL, Hyrax or other services; these are transparently managed through server adapters inside the node, virtually eliminating the need for alphabetization of node administrators.</p>
</li>
<li>
<p><strong>Client</strong> components are used by contributors to develop, validate and publish resources and semantic content (<strong>k.Modeler</strong>, an Integrated Development Environment (IDE) for semantic modeling), and by end users (<strong>k.Explorer</strong>) to access modeling services and specialized applications built for the platform and delivered through the web.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Additional server components serve specific needs on the k.LAB network and are of less common application in partner sites. Among them the following are noteworthy:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The <em>hub</em> server, <strong>k.Hub</strong>, manages authentication and organizes node access for authenticated engines. The Integrated Modeling Partnership manages a set of nodes and a main hub, and releases site certificates that enable nodes to be connected to form the platform. Partners that need to manage users locally may also deploy and connect a hub, although this is normally only convenient in large deployments.</p>
</li>
<li>
<p>A <em>semantic server</em> collects and indexes the semantic knowledge from the worldview and all public projects, constantly compiling and revising documentation and use cases to assist users in the semantic annotation process. Users can look up annotations made by others and access hyperlinked, evolving descriptions of each concept and predicate. The semantic server can be connected to the k.Modeler editor to provide inline logical validation of logical expressions in models being developed, and a suggestion service that can find and propose comparisons with use cases extracted from peer-reviewed public projects. Through the use of specialized metadata inserted in k.IM source files, the server can be integrated with the editors so that assistance is available directly, to ease the development of semantic content as much as possible. The semantic server is in development and is not available to the general public yet.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Other, less critical server components are in development and are not discussed here. Among these, a statistics server collects anonymized information from successful and unsuccessful resolutions and processes them using machine learning techniques to improve the resolution algorithm.</p>
</div>
</div>
<div class="sect2">
<h3 id="_the_k_lab_logical_layers">1.2. The k.LAB logical layers</h3>
<div class="paragraph">
<p>The set of active, connected nodes and engines at any given time forms what can be seen collectively as a distributed container, where scientific knowledge is found in <strong>three layers</strong> handling information at increasing levels of abstraction: the <em>resources</em>, <em>semantic</em> and <em>reactivity</em> layers. The first can be seen as a data curation platform based on modern linked data concepts, optimized for generality of the data model, semantic annotation and deployment. Semantic and reactive content for the platform is developed in the respective layers using two specialized languages, <em>k.IM</em> for semantic resources and <em>k.Actors</em> for rective behaviors and applications. The modeler IDE (<em>k.Modeler</em>) provides drag-and-drop interfaces to build resources and a specialized editing and debugging environment for k.LAB projects, supporting both k.IM and k.Actors development.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The <strong>resources</strong> layer provides a <em>protocol</em> for conventional data and computational resources or services to interoperate at the data level, matching identifiers, data types and metadata through a uniform API. Nodes and client applications include interfaces to manage development and submission of knowledge to the resources layer, to be published and curated either on-site or through hosting providers with full control of licensing and access.</p>
</li>
<li>
<p>The <strong>semantic</strong> layer provides a <em>language</em> that enables annotating resources through semantically explicit logical expressions, ensuring findability, interoperability and accessibility through purely logical queries, validating consistency and producing mediation strategies through machine reasoning and logical inference. The semantic layer uses the <strong>k.IM</strong> language to specify semantic knowledge (compatible with W3-endorsed <a href="https://www.w3.org/TR/owl-guide/">OWL 2</a>) and models; these specifications, collected into namespaces and projects, can be deployed to k.LAB Nodes for the k.LAB inference engines to find, rank and use.</p>
</li>
<li>
<p>The <strong>reactivity</strong> layer provides <em>behaviors</em> for the scientific artifacts produced by running queries in the semantic layer TURNING THEM INTO AGENTS. Reactive observations exist in k.LAB Engines and can react to each other either locally (within the same engine) or remotely. The reactivity layer enables distributed agent-based simulations and computations that automatically adapt to changing conditions or states. The <strong>k.Actors</strong> language is used to define behaviors for the reactivity layer. As a special case, behaviors bound to users and sessions can be used to quickly develop specialized interactive applications that run on the platform through web browsers.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The separation of concerns and APIs in the three layers maximizes their value: for example, the resources layer can be seen through different semantics, therefore serving different purposes in different networks by reinterpreting it through the logical "lens" of a differently configured semantic layer.</p>
</div>
</div>
<div class="sect2">
<h3 id="_accessing_the_system">1.3. Accessing the system</h3>
<div class="paragraph">
<p>GENERAL ARCHITECTURE: non-semantic resources (data, model components) annotated with semantics to produce <em>models</em> which can be <em>contextualized</em> in a space and time <em>context</em> to produce <em>observations</em> that describe those concepts in the context. These can be potentially provided with <em>behaviors</em>. Subito: EXAMPLE OF USE (model x as). Source (model urn as). Internals first: literals (model 1 as), processing (model X as using &#8230;&#8203;.).
<strong>Usage configurations</strong>: [DISCUSS END-USER (+k.Apps) vs MODELER vs PRODUCTION API USAGE vs PROVIDER, NODE/SITE ADMINISTRATOR] The k.LAB engine, a server-side component, can also be run at the client side in a local configuration, so that new content can be developed and tested in a sandboxed environment before publishing, with full access to public resources. Such client use is supported and facilitated by a small, downloadable <a href="https://integratedmodelling.org/get_started">control center application</a> that removes the complexities linked to installing, upgrading, starting and stopping the engine or the IDE. The k.LAB distributed paradigm supports and enforces a model where information remains under the ownership of its authoritative sources while maximizing its availability and interoperability, compatibly with both public and commercial services thanks to careful attribution and to state-of-the-art encryption, access control and security.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_resource_layer">2. The resource layer</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Shared resources available on the network have URNs (data, computations), geometry, and data type. One or more inputs/outputs and attributes. Simple API encompasses all conventional computations. Main service: resolve URN in context &#8594; return non-semantic artifact. If resource is computed, submitting input values may be necessary and the geometry specifies the form.</p>
</div>
<div class="paragraph">
<p>Adapters (for data, data services, computations, modeling services from WPS to large models). Current adapters for x&#8230;&#8203;.
I/O: modeler, node web UI
Lifecycle and rolling peer review. URN or DOIs (eventually). In special cases handled by the k.IM language, also literals or function calls. Clients. Permissions and access.</p>
</div>
<div class="paragraph">
<p>Besides data: resources are also "internally" implemented algorithms (from the core software or plug-in extensions) called as functions; literal values; or special URNs handled directly w/o referring to external or imported data (e.g. random). Uniformity with "function calls" makes it possible to insulate all the semantics within the semantic layer.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_semantic_modeling">3. Semantic modeling</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Semantic modeling enables the <em>semantic annotation</em> of non-semantic resources based on a shared <em>worldview</em> (a logically organized knowledge base containing concepts and relationships) and allow its linking to resource URNs by way of <em>models</em>, i.e. semantic annotations that specify the meaning associated with resources and, when applicable, with their inputs, outputs and attributes. As a non-semantic resource can represent both data and computations, k.LAB treats data annotations and semantically annotated algorithms uniformly; as a result, we use the term <em>model</em> to refer to both. The pool of models available on the k.LAB nodes connected to a session constitutes the semantic layer, which is searched by the resolution algorithm to resolve a logical query to a result artifact.</p>
</div>
<div class="paragraph">
<p>All semantic assets, from the knowledge base itself (concepts, relationships) to all semantically annotated content (data, algorithms) are specified in the <strong>k.IM language</strong>. While the underlying knowledge model for k.IM is the W3 standard OWL2 (to which all logical k.IM specifications can be translated), k.IM&#8217;s close resemblance to the structure of the English language makes it uncommonly readable:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-kim" data-lang="kim">model occurrence of agriculture:Pollinator biology:Insect caused by earth:Weather
	observing
		earth:AtmosphericTemperature in Celsius named air_temperature,
		earth:SolarRadiation in J named solar_radiation
	set to [0.62 + 1.027 * air_temperature + 0.006 * solar_radiation];</code></pre>
</div>
</div>
<div class="paragraph">
<p>In a departure from other ontology platforms, k.LAB admits, for the specification of semantics, logical expressions that combine predicates, operators and nouns in a fashion reminding of the grammar structure of the English language. For example, the k.IM statement <code>im:Net value of ecology:Pollination</code> (an <em>observable expression</em>, or <em>observable</em> in short) contains a predicate (<code>im:Net</code>) and a semantic operator <code>value of</code> which affects the meaning of the process concept <code>ecology:Pollination</code> and transforms it into the concept representing its quantifiable value. This <em>linguistic</em> articulation is key not only to the usability and parsimony of the underlying knowledge base, which can remain small and learnable because of the combination and reuse of terms and operators, but also to the functioning of the machine reasoning underlying the resolution algorithm, which can reason independently on the different logical dimensions of an observable and infer computations that would otherwise require specialized, <em>ad-hoc</em> modeling. Lacking specific models for a complex observable, each logical dimension of it may be <em>resolved</em> to one or more models which handle that specific component, and the set of models can be ranked for best fit to the context before selecting the most appropriate. The computations specified by the model are then assembled into a non-semantic <em>dataflow</em> (algorithm) that produces the desired result, and can, if wished, be saved as a non-semantic resource for future reuse.</p>
</div>
<div class="paragraph">
<p>It is typical of k.LAB models to be very short, simple and readable. Every model, with few exceptions, resolves <em>one</em> observable expression, with any required inputs stated merely as semantics; as a result, each model, by design, can be run and tested independently as a self-contained module. For example, the model below</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-kim" data-lang="kim">model occurrence of earth:Region with im:Still earth:PrecipitationVolume
	observing
		earth:Upstream im:Area in m^2 named contributing_area,
		geography:Slope in degree_angle named slope
	set to [
		def sloperadians = Math.tan((slope*1.570796) / 90)
	  	return Math.log((contributing_area+1) / Math.tan((sloperadians+0.001)));
	];</code></pre>
</div>
</div>
<div class="paragraph">
<p>requires observations of geographical slope and upstream drainage area to compute its output, a commonly used hydrological quantity (topographic wetness index) interpreted here through the semantics of "occurrence of region with retained precipitation", a 0-1 probability in k.LAB. None of the complex calculations required to compute the inputs needs to be part of the model, as their semantics (<code>earth:Upstream im:Area</code> and <code>geography:Slope</code>) is resolved at run time to the most appropriate model for the context when the primary observable is queried. The context can consist of a single point in space or of a gridded or polygon-based spatial coverage, without any modification to the model. When the model logics require that certain dependencies are satisfied in a specific way, scoping rules in k.IM can be used to ensure that specific models (or models for a specified subset) are chosen to satisfy the desired dependencies. It is also possible to use (libraries of) <em>non-semantic models</em> to refer to specific computations whose semantics is deemed not worth exposing, ensuring linkage with conventionally used metrics without sacrificing modularity or requiring overly difficult semantic characterization.</p>
</div>
<div class="paragraph">
<p>In many situations, models can be written independent of the specific spatial and temporal context in which they will be run, and often even in ways that are compatible with different interpretations of space and time. When that is not convenient, language constructs can be used to lock a model or namespace so that it is only applied to specified representations or ranges of extents and/or resolutions in both space and time, as well as to override the priorities in the resolution algorithm to handle any special need of the models or of the resources they use. Negotiation of inputs, outputs, data format, units or currencies, visualization and contextual validation are by default left to the k.LAB runtime. Writing models this way enforces discipline and maximizes clarity, readability and parsimony: contributors only write the core of the algorithm that leads to one specific observation, leaving every other aspect (including the selection and computation of any inputs) to the resolver and the k.LAB runtime.</p>
</div>
<div class="sect2">
<h3 id="_semantic_mediation_and_inference_in_support_of_modeling">3.1. Semantic mediation and inference in support of modeling</h3>
<div class="paragraph">
<p>In simple cases, the query "observe <em>observable</em> in <em>context</em>" is answered by locating a model annotating a data source as an observation of the specified observable. For example, setting the context to a geographical region (e.g. a country&#8217;s extent with a spatial grid model at 100m resolution and temporal context, e.g. the year 2010) and querying an observable such as <code>geography:Elevation in m</code> may retrieve, among others, the following model:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-kim" data-lang="kim">model im.data:geography:morphology:dem90 as geography:Elevation in m;</code></pre>
</div>
</div>
<div class="paragraph">
<p>which annotates a network-available resource specified by the URN <code>im.data:geography:morphology:dem90</code> as an observation of the <code>geography:Elevation</code> concept. The URN gives access to metadata including the original spatial and temporal coverage and resolution, through which the model, whose semantics is identical to the query&#8217;s, can be ranked for match to the context. If the model is deemed to be the best match, the k.LAB engine will translate it into a set of processing steps (in this case simply a resource retrieval operation plus any necessary mediation) and pass the resulting <em>dataflow</em> to the runtime to compute and produce the resulting <em>observation</em>, in this case a raster map of elevation, with 100m resolution, reflecting the boundaries and time of the context; the dataflow will include any necessary reprojection, resampling, or unit transformation to match the query and the context. Other models may compete for the choice, made on the basis of criteria such as resolution and extent match, specificity, semantic match, and including criteria such as peer review results or usage feedback for the original data. If the chosen model only partially covers the context, additional models may contribute to its complete characterization, as long as their ranks are close enough.</p>
</div>
<div class="paragraph">
<p>Besides such simple and direct matches, machine reasoning backed by an observation-centered (as opposed to reality-centered) ontological framework can enable more sophisticated observation tasks that do not correspond to readily available annotations and are normally only possible through specialized, time-consuming work. In a straightforward example, attributes such as <code>im:Normalized</code> may be prepended to another observable to affect the result, where the attribute would be resolved to an independent model (<code>model im:Normalized using &lt;normalization function&gt;</code>), possibly restricted to certain classes of observables (e.g. <code>model im:Normalized of im:Quantity &#8230;&#8203;</code> to restrict its application to numerically quantifiable observables) and used to modify a straight observation of <code>geography:Elevation</code> if the normalized observable cannot be resolved directly. More interestingly, resolution strategies may cross inherency barriers to infer the best observation strategy when a direct match is not available. For example, a hypothetical query for <code>(ecology:AboveGround ecology:Biomass) of biology:Eucalyptus biology:Tree</code> <sup class="footnote">[<a id="_footnoteref_1" class="footnote" href="#_footnotedef_1" title="View footnote.">1</a>]</sup> operated in the same country context would refer, by virtue of the inherency operator <code>of</code>, to a quality (above-ground biomass) inherent to a particular subset (Eucalyptus) of the observations of a secondary subject (Tree) located in the primary context of the query (a geographical region). It would be resolved by the following strategy:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Locate a model for the original observable, <code>(ecology:AboveGround ecology:Biomass) of biology:Eucalyptus biology:Tree</code>, that is compatible with the context of observation. If found, resolve using it. Otherwise</p>
</li>
<li>
<p>Locate a model of the inherent subject, <code>biology:Eucalyptus biology:Tree</code>; if found, use it to generate an observation for each eucalyptus tree in the region, and for each of them locate a model of <code>(ecology:AboveGround ecology:Biomass)</code>. If an "eucalyptus tree" model cannot be resolved</p>
</li>
<li>
<p>Locate a model capable of instantiating every <code>biology:Tree</code> in the region; if found, locate a classifier model capable of either 1) checking if the tree is eucalyptus or not (<code>model biology:Eucalyptus of biology:Tree</code>), or 2) attributing the abstract identity (<code>biology:Species</code>) of which <code>biology:Eucalyptus</code> is a subclass (<code>model biology:Species of biology:Tree</code>). Such a model would be applied to classify the tree observations, only keeping those that classify as eucalyptus.</p>
</li>
<li>
<p>If eucalyptus trees are resolved successfully, locate a model of <code>(ecology:AboveGround ecology:Biomass)</code> for each tree to compute the biomass in the context of each. If successful, apply a <em>dereifying</em> operation to complete the observation, turning the "above ground biomass" values observed in the context of each tree into the quality "above ground biomass of eucalyptus tree" observed in the context region.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Similar reasoning strategies can be applied to a large set of situations, using semantic inference driven by the phenomenological understanding of the entities involved and the observation process applied to them. For example, a query for <code class="source kim">presence of biology:Tree</code> could be satisfied, when not resolvable directly, by a model of <code>(ecology:AboveGround ecology:Biomass) of biology:Tree</code> because biomass (a <code>im:Mass</code> in a higher-level ontology) is an <em>extensive</em> property, therefore its non-zero value implies the existence of its inherent subject. The presence can be computed as a true/false value attributed to the context wherever the biomass of any tree is nonzero. In another commonly encountered use case, qualities that can only be correctly computed in specifically delineated contexts (for example hydrological qualities, such as "upstream area", which only produce correct results when computed in a correctly delineated river basin) can be automatically computed in arbitrary contexts by first looking up a model to delineate all the relevant contexts (river basins) intersecting the areas, then applying the necessary models to compute the qualities inherently to those, then re-distributing the values over the desired context. Such behavior can be automated simply on semantic grounds by defining a concept such as</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-kim" data-lang="kim">area ContributingArea
	is earth:Upstream im:Area within hydrology:RiverBasin;</code></pre>
</div>
</div>
<div class="paragraph">
<p>where the 'within' operator mandates a RiverBasin context for the quality, which will trigger the distributed resolution process described whenever ContributingArea is queried in any context where river basins can be observed. The same considerations hold for more complex observables such as processes, which have the ability of affecting the value of qualities through time and to generate events or other objects; these, in turn, can be the context for other qualities or processes. The ability of automatically negotiating mediations based on inherency and phenomenological reasoning multiplies the capability of connecting diverse models without error, offering integration possibilities orders of magnitude beyond those allowed by semantic matching alone. Such tasks require specific planning and significant technical expertise and time to perform in conventional ways.</p>
</div>
<div class="paragraph">
<p>Much of the power of k.LAB comes from the fact that models pertaining to the different sides of a problem may be provided and shared by independent modelers, with no need for any coordination besides adhering to the same worldview. Each model serves multiple potential purposes and does not <em>add to</em>, but <em>multiplies</em> the value of other knowledge on the platform, just like the words in a language. This is particularly advantageous when the problem area spans multiple disciplines, expertises and languages, emphasizing the importance of a collaboratively built and endorsed <em>worldview</em>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_the_worldview">3.2. The worldview</h3>
<div class="paragraph">
<p>Both annotation and inference, as described above, require a set of <em>ontologies</em> that define the realm of knowledge that can be integrated and conform with the foundational principles of k.LAB&#8217;s observational model. We refer to this set of ontologies as the <em>wordlview</em>, a set of k.IM projects that are automatically synchronized to all users that adopt it. Worldviews are linked to user profiles and may be as many as needed; the development of a worldview, however, is a large collaborative endeavor and to date, there is one worldview (the <code>im</code> worldview, for Integrated Modeling) that is under development within the k.LAB team and an extended group of collaborators. As a worldview is meant to describe <em>observation</em> of reality, not reality itself, it is naturally aware of <em>scale</em> and its semantics differentiates observables not only by phenomenological nature but also by the nature of the observation process applicable to them. For example, events vs processes. Scale of observation (range thereof) is key to semantics and to compatibility of worldviews. More than 1 possible but we&#8217;re working on one, scaled around human observation (wouldn&#8217;t fit large or small, such as field of application of relativity or quantum physics. Must be shared, can&#8217;t be owned.</p>
</div>
<div class="sect3">
<h4 id="_authorities">3.2.1. Authorities</h4>
<div class="paragraph">
<p>Identifying identities such as taxonomic or chemical species presents a challenge as their number is virtually infinite: as a result, ontologies often provide <em>some</em> of the ones most likely needed by the communities of reference, but it is impossible to address all use cases and even importing specialized ontologies (such as CHEBI for chemical identities) risks overwhelming the reasoner with too many (and still often not enough) concepts, or creating unnecessary usage conflict with the same concepts from other ontologies. In k.LAB, this problem is obviated through the introduction of <em>authorities</em>, a mechanism to interface with external vocabularies that enjoy broad community acceptance, fully integrated in the k.IM language. Such vocabularies are seen by contributors and users as externalized namespaces. An authoritative identity takes the form <code>IUPAC:water</code>, easily distinguished from other concepts by its uppercase namespace tag (a regular concept would have a lowercase namespace, e.g. <code>geography:Slope</code>). Its use in k.IM triggers validation of the concept ID (<code>water</code>) using an online service tied to the authority (<code>IUPAC</code>) which is advertised by nodes in the k.LAB network. Upon successful validation, an identity concept is produced for the statement whose definition is identical and stable at all points of use. This mechanism allows externalizing large vocabularies (such as the IUPAC catalog of chemical species or the GBIF taxonomy identifiers) and structured specification conventions (such as the World Reference Base for soil types) that are validated and turned into stable, k.LAB-aligned semantics at the moment of their use. Another advantage of many authorities is flexibility of usage: for example, <code>IUPAC:water</code> and <code>IUPAC:H2O</code> are valid identifiers that can be used in k.IM observables as written [EXAMPLE] and translate to the same concept (the chemical identity corresponding to water, encoded internally as the standard InChl key) using a IUPAC-endorsed catalog service. The k.LAB stack provides content contributors with assisted search interface and intelligent editor support with inline, "as-you-type" validation and documentation.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_learning_models">3.3. Learning models</h3>
<div class="paragraph">
<p>Model vs. Learn - produces a computable resource (dataflow) that can be stored with a URN, independent of semantics. This includes "calibration" and "validation". Standard machine learning (show example). Calibration or other model inference. Model for many applications</p>
</div>
</div>
<div class="sect2">
<h3 id="_views_documentation_provenance">3.4. Views, documentation, provenance</h3>

</div>
</div>
</div>
<div class="sect1">
<h2 id="_behaviors_and_applications">4. Behaviors and applications</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_applications_client_software">4.1. Applications, Client software</h3>

</div>
</div>
</div>
<div class="sect1">
<h2 id="_current_status">5. Current status</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Used currently at production levels for applications such as the general ARIES explorer and specialized apps like ARIES for SEEA. Visualization and reporting at near-feature completion for current uses.
Installable containers for nodes and engines but few partner nodes besides the central team and the UN.
Functionality completion is about 90%, enough for current applications but still needing work for full-scale agent-based modeling, real-time applications and other types of use. k.LAB still not at version 1.0, predicted in 1+ year after full feature completion and documentation.
Adapters for most important data formats, services and protocols including &#8230;&#8203; (SDMX, OGC, &#8230;&#8203; ). Interfaces to contribute data/models are limited for now to the modeling environment k.Modeler, which is functional but not suitable for non-technical users. More data submission aids to be developed in 2021 to support UN and other applications.
Limited funding for development but with high chance of continuation. Operation through preferred partnership models rather than grants, as continuity and talent retention are more important than large investments in one-off funding.
API is optimized for applications and use "within" the system using its own clients based on Project Explorer: more work needed for a stable API to be used independently.</p>
</div>
</div>
</div>
</div>
<div id="footnotes">
<hr>
<div class="footnote" id="_footnotedef_1">
<a href="#_footnoteref_1">1</a>. The <code>biology:Eucalyptus</code> species identity, used here for simplicity, would in reality be handled through a taxonomic authority: see the section <em>Authorities</em> below for details.
</div>
</div>
<div id="footer">
<div id="footer-text">
Version 1.0<br>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains("stemblock")) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>