= k.LAB: a semantic web platform for science
Technical note
v1.0, 2021-02-20
:doctype: article
:description: High-level technical description of k.LAB for technical partners
:kl: k.LAB
:kmod: k.Modeler
:kact: k.Actors
:keng: k.LAB Engine
:knod: k.LAB Node
:kim: k.IM
:ked: k.LAB Resource Editor
:pex: Project Explorer
:kex: k.LAB Explorer
:encoding: utf-8
:lang: en
:title-page:
:toc: left
:toclevels: 5
:sectnums:
:sectnumlevels: 5
:numbered:
:experimental:
:reproducible:
:icons: font
:listing-caption: Listing
:sectnums:
:autofit-option:
:mdash: &#8212;
:language: asciidoc
:title-logo-image: image:resources_handling/imgs/KLAB_LOGO.png[align=center]
:source-highlighter: highlightjs
:highlightjs-languages: kim, java
:highlightjs-theme: klab
:stem:

<<<

*Integrated modeling* is a practice meant to maximize the value of scientific information by ensuring its  _modularity_, _reusability_, _interoperability_ and _traceability_ throughout the scientific process. The k.LAB software, discussed here, is a full-stack solution for integrated modelling, supporting the production, curation, linking and deployment of scientific artifacts such as datasets, data services, modular model components and distributed computational services. The purpose of k.LAB is to ensure -- by _design_ rather than intention -- that the pool of such artifacts constitutes a seamless _knowledge commons_, readily actionable (by humans or machines) through the full realization of the _linked data_ paradigm [REF] augmented with semantics and powered by machine reasoning. This design enables automation of a wide range of modeling tasks that were previously only performable by experts and on an ad-hoc basis.

The {kl} platform directly addresses the four FAIR goals (Findable, Accessible, Interoperable and Reusable), introducing innovations particularly in the practice of semantic annotation,  which is reviewed into a modern, expressive approach meant to ease adoption by providers and users. To the four dimensions in FAIR, {kl} adds a _reactivity_ dimension, in line with the original vision of a semantic web: this dimension enables knowledge to also be _deployed_ in an _"internet of observations"_, creating _live_ artifacts that can interact, improve and evolve as new information appears on the network.

The central service in the k.LAB modeling API wraps the RESOLUTION ALGORITHM !!!! receives as input a logical query of the form "observe _concept_ in _context_" (e.g., "observe _change in land cover type_ in _Colombia, 2015-2020_", only slightly paraphrased from k.LAB's near-natural query formalism) and, in response, assembles, documents, initializes and runs a computation (called a _dataflow_) that produces the  *observation* of the concept that best fits the context, based on the integration of data and model components available in the k.LAB network. The observations output by the API request, along with the dataflow assembled to generate them, are themselves scientific artifacts -- automatically augmented with provenance records and user-readable documentation -- that can be exported and curated as needed. @!!!! The logical queries are also used to state model dependencies so that .... !!!!

Artificial intelligence, driven by both semantics (_machine reasoning_) and the analysis of previous outcomes (_machine learning_), satisfies the request using a shared, communally owned and curated knowledge base (the _worldview_, a set of ontologies) and the resource pool available at any given moment on the k.LAB network, by ranking, selecting, adapting, and connecting data and model components made available by independent and uncoordinated providers.

This document is a brief sketch of the {kl} main principles and architecture. Detailed documentation for {kl} is in development and is referenced where available.

## Architecture of the k.LAB platform

The open source k.LAB software stack includes five components that support the creation, maintenance and use of a distributed _semantic web platform_ where scientific information can be stored, published, curated and connected. The software is licensed through the Affero General Public License (AGPL) v.3.0 and is available for the most part at the https://bitbucket.org/integratedmodelling/klab[{kl} git repository].

### The software stack

* *Server* components are deployed by certified _partners_ to publish resources and semantic content (*{knod}*) and/or provide modeling services and applications (*{keng}*) to online users. Published resources can include both static data and dynamic computations, both of which may be hosted in source form at the node or linked to external data (e.g. WCS, WFS, OpenDAP) or computational services (e.g. OpenCPU). The k.Node software is deployed in containers that can be configured to host dedicated instances of Geoserver, PostgreSQL, Hyrax or other services; these are transparently managed through server adapters inside the node, virtually eliminating the need for alphabetization of node administrators.
* *Client* components are used by contributors to develop, validate and publish resources and semantic content (*k.Modeler*, an Integrated Development Environment (IDE) for semantic modeling), and by end users (*k.Explorer*) to access modeling services and specialized applications built for the platform and delivered through the web.

Additional server components serve specific needs on the {kl} network and are of less common application in partner sites. Among them the following are noteworthy:

* The _hub_ server, *k.Hub*, manages authentication and organizes node access for authenticated engines. The Integrated Modeling Partnership manages a set of nodes and a main hub, and releases site certificates that enable nodes to be connected to form the platform. Partners that need to manage users locally may also deploy and connect a hub, although this is normally only convenient in large deployments.
* A _semantic server_ collects and indexes the semantic knowledge from the worldview and all public projects, constantly compiling and revising documentation and use cases to assist users in the semantic annotation process. Users can look up annotations made by others and access hyperlinked, evolving descriptions of each concept and predicate. The semantic server can be connected to the {kmod} editor to provide inline logical validation of logical expressions in models being developed, and a suggestion service that can find and propose comparisons with use cases extracted from peer-reviewed public projects. Through the use of specialized metadata inserted in {kim} source files, the server can be integrated with the editors so that assistance is available directly, to ease the development of semantic content as much as possible. The semantic server is in development and is not available to the general public yet. 

Other, less critical server components are in development and are not discussed here. Among these, a statistics server collects anonymized information from successful and unsuccessful resolutions and processes them using machine learning techniques to improve the resolution algorithm.

### The {kl} logical layers

The set of active, connected nodes and engines at any given time forms what can be seen collectively as a distributed container, where scientific knowledge is found in **three layers** handling information at increasing levels of abstraction: the _resources_, _semantic_ and _reactivity_ layers. The first can be seen as a data curation platform based on modern linked data concepts, optimized for generality of the data model, semantic annotation and deployment. Semantic and reactive content for the platform is developed in the respective layers using two specialized languages, _{kim}_ for semantic resources and _{kact}_ for rective behaviors and applications. The modeler IDE (_{kmod}_) provides drag-and-drop interfaces to build resources and a specialized editing and debugging environment for {kl} projects, supporting both {kim} and {kact} development.

* The *resources* layer provides a _protocol_ for conventional data and computational resources or services to interoperate at the data level, matching identifiers, data types and metadata through a uniform API. Nodes and client applications include interfaces to manage development and submission of knowledge to the resources layer, to be published and curated either on-site or through hosting providers with full control of licensing and access. 
* The *semantic* layer provides a _language_ that enables annotating resources through semantically explicit logical expressions, ensuring findability, interoperability and accessibility through purely logical queries, validating consistency and producing mediation strategies through machine reasoning and logical inference. The semantic layer uses the **{kim}** language to specify semantic knowledge (compatible with W3-endorsed https://www.w3.org/TR/owl-guide/[OWL 2]) and models; these specifications, collected into namespaces and projects, can be deployed to {knod}s for the {kl} inference engines to find, rank and use.
* The *reactivity* layer provides _behaviors_ for the scientific artifacts produced by running queries in the semantic layer TURNING THEM INTO AGENTS. Reactive observations exist in {keng}s and can react to each other either locally (within the same engine) or remotely. The reactivity layer enables distributed agent-based simulations and computations that automatically adapt to changing conditions or states. The **{kact}** language is used to define behaviors for the reactivity layer. As a special case, behaviors bound to users and sessions can be used to quickly develop specialized interactive applications that run on the platform through web browsers.

The separation of concerns and APIs in the three layers maximizes their value: for example, the resources layer can be seen through different semantics, therefore serving different purposes in different networks by reinterpreting it through the logical "lens" of a differently configured semantic layer.

### Accessing the system

The {kl} system can be accessed through a client (usually an application running within the {kex} web platform, or the {kl} integrated development environment (IDE), {kmod}) or through its API by software applications. Providers of content may use the IDE or, in the near future, a content provider web interface available on all {klab} nodes. All users must be authenticated through a valid, secure certificate, which also establishes user permissions for the certificate holder. Permissions may limit access to reserved or private content, which may be uploaded as public or linked to specific users or user groups by its owners.

Regular users:: Non-technical users of the {kl} platform normally interact with the system through an instance of {kex} exposed by a networked {kl} engine (or cluster thereof). The basic {kex} interface is usable as a generic search-and-compute interface and allows users to easily set their context of interest to locations and times of interest. Queries are cached and suggestions are given based on the user's groups and previous queries, providing an experience similar to modern search platforms. As {kex} can be used as an application development platform (see further in this document), specific applications can be built on top of {kex} and given a specialized access URL. Such applications, like the recently deployed https://seea.un.org/content/aries-for-seea[ARIES for SEEA], look and feel like typical interactive web applications and can be developed and deployed with very minimal effort to assist specific classes of users.
Content providers and modelers:: The k.LAB engine, a server-side component, can also be run at the client side in a local configuration, so that new content can be developed and tested in a sandboxed environment before publishing, with full access to public resources. Such client use is supported and facilitated by a small, downloadable https://integratedmodelling.org/get_started[control center application] that removes the complexities linked to installing, upgrading, starting and stopping the engine or the {kmod} IDE. The IDE remains, at the time of this writing, the endorsed toolkit to prepare both semantic and non-semantic content for distribution and publish it to the network. In the near future, more direct pathways will be enabled so that data contributors can also provide content (particularly datasets) through less technical, web-based interfaces.
Applications and software usage:: The {kl} system provides a stable API for all its components, more notably the authenticating hub, the nodes and the engines. This API is used by all the {kl} client software but can be used independently to enact a "modeling as a service" paradigm whose primary service provided is the resolution algorithm. At the time of this writing, the API is mostly used through {kl}'s own client software, but ongoing projects and collaborations point to a more widespread integration of {kl} API services within foreign platforms and applications in the next months. In addition to direct use of REST endpoints, served by engine clusters operated by BC3 and partner institutions, clients for popular languages (Python, Javascript, R) will be made available based on demand to ease integration with existing applications.

In addition to uploading content to existing nodes, institutionals contributors can deploy {knod} software to deploy sites that contribute to the {kl} network while remaining fully in control of all distribution details. Nodes are deployed as containers that can be easily set up and authorized by certified partners. The k.LAB distributed paradigm supports and enforces a model where information remains under the ownership of its authoritative sources while maximizing its availability and interoperability, compatibly with both public and commercial services thanks to careful attribution and to state-of-the-art encryption, access control and security.

## The resource layer

Shared resources available on the network have URNs (data, computations), geometry, and data type. One or more inputs/outputs and attributes. Simple API encompasses all conventional computations. Main service: resolve URN in context -> return non-semantic artifact. If resource is computed, submitting input values may be necessary and the geometry specifies the form. 
 
Adapters (for data, data services, computations, modeling services from WPS to large models). Current adapters for x....
I/O: modeler, node web UI
Lifecycle and rolling peer review. URN or DOIs (eventually). In special cases handled by the {kim} language, also literals or function calls. Clients. Permissions and access.

Besides data: resources are also "internally" implemented algorithms (from the core software or plug-in extensions) called as functions; literal values; or special URNs handled directly w/o referring to external or imported data (e.g. random). Uniformity with "function calls" makes it possible to insulate all the semantics within the semantic layer. 

## Semantic modeling

Semantic modeling enables the _semantic annotation_ of non-semantic resources based on a shared _worldview_ (a logically organized knowledge base containing concepts and relationships) and allow its linking to resource URNs by way of _models_, i.e. semantic annotations that specify the meaning associated with resources and, when applicable, with their inputs, outputs and attributes. As a non-semantic resource can represent both data and computations, {kl} treats data annotations and semantically annotated algorithms uniformly; as a result, we use the term _model_ to refer to both. The pool of models available on the {kl} nodes connected to a session constitutes the semantic layer, which is searched by the resolution algorithm to resolve a logical query to a result artifact. 

All semantic assets, from the knowledge base itself (concepts, relationships) to all semantically annotated content (data, algorithms) are specified in the **{kim} language**. While the underlying knowledge model for {kim} is the W3 standard OWL2 (to which all logical {kim} specifications can be translated), {kim}'s close resemblance to the structure of the English language makes it uncommonly readable:

[source,kim]
----
model occurrence of agriculture:Pollinator biology:Insect caused by earth:Weather
	observing
		earth:AtmosphericTemperature in Celsius named air_temperature,
		earth:SolarRadiation in J named solar_radiation
	set to [0.62 + 1.027 * air_temperature + 0.006 * solar_radiation];
----

In a departure from other ontology platforms, k.LAB admits, for the specification of semantics, logical expressions that combine predicates, operators and nouns in a fashion modeled on the grammar of the English language. For example, the {kim} statement `im:Net value of ecology:Pollination` (an _observable expression_, or _observable_ in short) contains a predicate (`im:Net`) and a semantic operator `value of` which affects the meaning of the process concept `ecology:Pollination` and transforms it into the concept representing its quantifiable value. This _linguistic_ articulation is key not only to the usability and parsimony of the underlying knowledge base, which can remain small and learnable because of the combination and reuse of terms and operators, but also to the functioning of the machine reasoning underlying the resolution algorithm, which can reason independently on the different logical dimensions of an observable and infer computations that would otherwise require specialized, _ad-hoc_ modeling. Lacking specific models for a complex observable, each logical dimension of it may be _resolved_ to one or more models which handle that specific component, and the set of models can be ranked for best fit to the context before selecting the most appropriate. The computations specified by the model are then assembled into a non-semantic _dataflow_ (algorithm) that produces the desired result, and can, if wished, be saved as a non-semantic resource for future reuse. 

The specialized {kim} editor provided with {kl} further facilitates the use and recognition of semantics by color-coding the fundamental classes of knowledge represented by concepts (blue for predicates, such as attributes, roles, realms or identities; green for quantifiable or categorizable qualities; red, green/yellow, yellow and brown respectively for processes, events, relationships and subjects). It is typical of k.LAB models to be very short, simple and easily readable. Every model, with few exceptions, resolves _one_ observable expression, with any required inputs stated merely as their semantics; as a result, each model, by design, can be run and tested independently. For example, the model below 

[source,kim,linenumbers]
----
model occurrence of earth:Region with im:Still earth:PrecipitationVolume
	observing 
		earth:Upstream im:Area in m^2 named contributing_area,
		geography:Slope in degree_angle named slope
	set to [
		def sloperadians = Math.tan((slope*1.570796) / 90) 
	  	return Math.log((contributing_area+1) / Math.tan((sloperadians+0.001)));
	];
----

requires observations of geographical slope and upstream drainage area to compute its output, a commonly used hydrological quantity (topographic wetness index) interpreted here through the semantics of "occurrence of region with retained precipitation", a 0-1 probability in {kl}. None of the complex calculations required to compute the inputs needs to be part of the model, as their semantics (`earth:Upstream im:Area` and `geography:Slope`) is resolved at run time to the most appropriate model for the context when the primary observable is queried. The context can consist of a single point in space or of a gridded or polygon-based spatial coverage, without any modification to the model. When the model logics require that certain dependencies are satisfied in a specific way, scoping rules in {kim} can be used to ensure that specific models (or models for a specified subset) are chosen to satisfy the desired dependencies. It is also possible to use (libraries of) _non-semantic models_ to refer to specific computations whose semantics is deemed not worth exposing, ensuring linkage with conventionally used metrics without sacrificing modularity or requiring overly difficult semantic characterization. 

In many situations, models can be written independent of the specific spatial and temporal context in which they will be run, and often even in ways that are compatible with different interpretations of space and time. When that is not convenient, language constructs can be used to lock a model or namespace so that it is only applied to specified representations or ranges of extents and/or resolutions in both space and time, as well as to override the priorities in the resolution algorithm to handle any special need of the models or of the resources they use. Negotiation of inputs, outputs, data format, units or currencies, visualization and contextual validation are by default left to the k.LAB runtime. Writing models this way enforces discipline and maximizes clarity, readability and parsimony: contributors only write the core of the algorithm that leads to one specific observation, leaving every other aspect (including the selection and computation of any inputs) to the resolver and the k.LAB runtime.

### Semantic mediation and inference in support of modeling

In simple cases, the query "observe _observable_ in _context_" is answered by locating a model annotating a data source as an observation of the specified observable. For example, setting the context to a geographical region (e.g. a country's extent with a spatial grid model at 100m resolution and temporal context, e.g. the year 2010) and querying an observable such as `geography:Elevation in m` may retrieve, among others, the following model:

[source,kim]
----
model im.data:geography:morphology:dem90 as geography:Elevation in m;
----

which annotates a network-available resource specified by the URN `im.data:geography:morphology:dem90` as an observation of the `geography:Elevation` concept. The URN gives access to metadata including the original spatial and temporal coverage and resolution, through which the model, whose semantics is identical to the query's, can be ranked for match to the context. If the model is deemed to be the best match, the {kl} engine will translate it into a set of processing steps (in this case simply a resource retrieval operation plus any necessary mediation) and pass the resulting _dataflow_ to the runtime to compute and produce the resulting _observation_, in this case a raster map of elevation, with 100m resolution, reflecting the boundaries and time of the context; the dataflow will include any necessary reprojection, resampling, or unit transformation to match the query and the context. Other models may compete for the choice, made on the basis of criteria such as resolution and extent match, specificity, semantic match, and including criteria such as peer review results or usage feedback for the original data. If the chosen model only partially covers the context, additional models may contribute to its complete characterization, as long as their ranks are close enough.

Besides such simple and direct matches, machine reasoning backed by an observation-centered (as opposed to reality-centered) ontological framework can enable more sophisticated observation tasks that do not correspond to readily available annotations and are normally only possible through specialized, time-consuming work. In a straightforward example, attributes such as `im:Normalized` may be prepended to another observable to affect the result, where the attribute would be resolved to an independent model (`model im:Normalized using <normalization function>`), possibly restricted to certain classes of observables (e.g. `model im:Normalized of im:Quantity ...` to restrict its application to numerically quantifiable observables) and used to modify a straight observation of `geography:Elevation` if the normalized observable cannot be resolved directly. More interestingly, resolution strategies may cross inherency barriers to infer the best observation strategy when a direct match is not available. For example, a hypothetical query for `(ecology:AboveGround ecology:Biomass) of biology:Eucalyptus biology:Tree` footnote:[The `biology:Eucalyptus` species identity, used here for simplicity, would in reality be handled through a taxonomic authority: see the section _Authorities_ below for details.] operated in the same country context would refer, by virtue of the inherency operator `of`, to a quality (above-ground biomass) inherent to a particular subset (Eucalyptus) of the observations of a secondary subject (Tree) located in the primary context of the query (a geographical region). It would be resolved by the following strategy: 

1. Locate a model for the original observable, `(ecology:AboveGround ecology:Biomass) of biology:Eucalyptus biology:Tree`, that is compatible with the context of observation. If found, resolve using it. Otherwise
2. Locate a model of the inherent subject, `biology:Eucalyptus biology:Tree`; if found, use it to generate an observation for each eucalyptus tree in the region, and for each of them locate a model of `(ecology:AboveGround ecology:Biomass)`. If an "eucalyptus tree" model cannot be resolved
3. Locate a model capable of instantiating every `biology:Tree` in the region; if found, locate a classifier model capable of either 1) checking if the tree is eucalyptus or not (`model biology:Eucalyptus of biology:Tree`), or 2) attributing the abstract identity (`biology:Species`) of which `biology:Eucalyptus` is a subclass (`model biology:Species of biology:Tree`). Such a model would be applied to classify the tree observations, only keeping those that classify as eucalyptus. 
4. If eucalyptus trees are resolved successfully, locate a model of `(ecology:AboveGround ecology:Biomass)` for each tree to compute the biomass in the context of each. If successful, apply a _dereifying_ operation to complete the observation, turning the "above ground biomass" values observed in the context of each tree into the quality "above ground biomass of eucalyptus tree" observed in the context region.

Similar reasoning strategies can be applied to a large set of situations, using semantic inference driven by the phenomenological understanding of the entities involved and the observation process applied to them. For example, a query for [.source.kim]`presence of biology:Tree` could be satisfied, when not resolvable directly, by a model of `(ecology:AboveGround ecology:Biomass) of biology:Tree` because biomass (a `im:Mass` in a higher-level ontology) is an _extensive_ property, therefore its non-zero value implies the existence of its inherent subject. The presence can be computed as a true/false value attributed to the context wherever the biomass of any tree is nonzero. In another commonly encountered use case, qualities that can only be correctly computed in specifically delineated contexts (for example hydrological qualities, such as "upstream area", which only produce correct results when computed in a correctly delineated river basin) can be automatically computed in arbitrary contexts by first looking up a model to delineate all the relevant contexts (river basins) intersecting the areas, then applying the necessary models to compute the qualities inherently to those, then re-distributing the values over the desired context. Such behavior can be automated simply on semantic grounds by defining a concept such as

[source,kim]
----
area ContributingArea
	is earth:Upstream im:Area within hydrology:RiverBasin;
----

where the 'within' operator mandates a RiverBasin context for the quality, which will trigger the distributed resolution process described whenever ContributingArea is queried in any context where river basins can be observed. The same considerations hold for more complex observables such as processes, which have the ability of affecting the value of qualities through time and to generate events or other objects; these, in turn, can be the context for other qualities or processes. The ability of automatically negotiating mediations based on inherency and phenomenological reasoning multiplies the capability of connecting diverse models without error, offering integration possibilities orders of magnitude beyond those allowed by semantic matching alone. Such tasks require specific planning and significant technical expertise and time to perform in conventional ways.

Much of the power of {kl} comes from the fact that models pertaining to the different sides of a problem may be provided and shared by independent modelers, with no need for any coordination besides adhering to the same worldview. Each model serves multiple potential purposes and does not _add to_, but _multiplies_ the value of other knowledge on the platform, just like the words in a language. This is particularly advantageous when the problem area spans multiple disciplines, expertises and languages, emphasizing the importance of a collaboratively built and endorsed _worldview_. 

### The worldview

Both annotation and inference, as described above, require a set of _ontologies_ that define the realm of knowledge that can be integrated and conform with the foundational principles of {kl}'s observational model. We refer to this set of ontologies as the _wordlview_, a set of {kim} projects that are automatically synchronized to all users that adopt it. Worldviews are linked to user profiles and may be as many as needed; the development of a worldview, however, is a large collaborative endeavor and to date, there is one worldview (the `im` worldview, for Integrated Modeling) that is under development within the {kl} team and an extended group of collaborators. As a worldview is meant to describe _observation_ of reality, not reality itself, it is naturally aware of _scale_ and its semantics differentiates observables not only by phenomenological nature but also by the nature of the observation process applicable to them. For example, events vs processes. Scale of observation (range thereof) is key to semantics and to compatibility of worldviews. More than 1 possible but we're working on one, scaled around human observation (wouldn't fit large or small, such as field of application of relativity or quantum physics. Must be shared, can't be owned. 

#### Authorities

Identifying identities such as taxonomic or chemical species presents a challenge as their number is virtually infinite: as a result, ontologies often provide _some_ of the ones most likely needed by the communities of reference, but it is impossible to address all use cases and even importing specialized ontologies (such as CHEBI for chemical identities) risks overwhelming the reasoner with too many (and still often not enough) concepts, or creating unnecessary usage conflict with the same concepts from other ontologies. In {kl}, this problem is obviated through the introduction of _authorities_, a mechanism to interface with external vocabularies that enjoy broad community acceptance, fully integrated in the k.IM language. Such vocabularies are seen by contributors and users as externalized namespaces. An authoritative identity takes the form `IUPAC:water`, easily distinguished from other concepts by its uppercase namespace tag (a regular concept would have a lowercase namespace, e.g. `geography:Slope`). Its use in {kim} triggers validation of the concept ID (`water`) using an online service tied to the authority (`IUPAC`) which is advertised by nodes in the k.LAB network. Upon successful validation, an identity concept is produced for the statement whose definition is identical and stable at all points of use. This mechanism allows externalizing large vocabularies (such as the IUPAC catalog of chemical species or the GBIF taxonomy identifiers) and structured specification conventions (such as the World Reference Base for soil types) that are validated and turned into stable, {kl}-aligned semantics at the moment of their use. Another advantage of many authorities is flexibility of usage: for example, `IUPAC:water` and `IUPAC:H2O` are valid identifiers that can be used in k.IM observables as written [EXAMPLE] and translate to the same concept (the chemical identity corresponding to water, encoded internally as the standard InChl key) using a IUPAC-endorsed catalog service. The k.LAB stack provides content contributors with assisted search interface and intelligent editor support with inline, "as-you-type" validation and documentation.

### Learning models

Model vs. Learn - produces a computable resource (dataflow) that can be stored with a URN, independent of semantics. This includes "calibration" and "validation". Standard machine learning (show example). Calibration or other model inference. Model for many applications

### Views, documentation, provenance

## Behaviors and applications

### Applications, Client software 

## Current status

Used currently at production levels for applications such as the general ARIES explorer and specialized apps like ARIES for SEEA. Visualization and reporting at near-feature completion for current uses.
Installable containers for nodes and engines but few partner nodes besides the central team and the UN.
Functionality completion is about 90%, enough for current applications but still needing work for full-scale agent-based modeling, real-time applications and other types of use. {kl} still not at version 1.0, predicted in 1+ year after full feature completion and documentation.
Adapters for most important data formats, services and protocols including ... (SDMX, OGC, ... ). Interfaces to contribute data/models are limited for now to the modeling environment {kmod}, which is functional but not suitable for non-technical users. More data submission aids to be developed in 2021 to support UN and other applications.
Limited funding for development but with high chance of continuation. Operation through preferred partnership models rather than grants, as continuity and talent retention are more important than large investments in one-off funding.
API is optimized for applications and use "within" the system using its own clients based on {kex}: more work needed for a stable API to be used independently.